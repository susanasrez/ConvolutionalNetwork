{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyecto inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando cpu para entrenar\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando {device} para entrenar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\marap\\\\OneDrive\\\\Documentos\\\\ProyectosVisual\\\\ConvolutionalNetwork\\\\ConvolutionalNetwork\\\\real_and_fake_face'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = os.path.abspath('real_and_fake_face/')\n",
    "INITIAL_SIZE_OF_IMAGES = (128, 128)\n",
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(INITIAL_SIZE_OF_IMAGES),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=DATASET, transform=data_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el tama침o de los conjuntos de validaci칩n y prueba\n",
    "valid_size = int(0.8 * len(train_loader.dataset))\n",
    "test_size = len(train_loader.dataset) - valid_size\n",
    "\n",
    "# Crear subconjuntos para validaci칩n y prueba\n",
    "valid_dataset, test_dataset = torch.utils.data.random_split(train_loader.dataset, [valid_size, test_size])\n",
    "\n",
    "# Crear DataLoaders para los conjuntos de validaci칩n y prueba\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
